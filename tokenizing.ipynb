{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import GPT2Tokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "with open('dataset_unprocessed.txt', 'rb') as input_file:\n",
    "    dataset:DatasetDict = pickle.load(input_file) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21755681\n",
      "Features: Dialogue\n",
      "Words: quit, oak, gloomy\n",
      "Summary: Sara and Ben were playing in the park, but Sara wanted to go home because it was cold and dark. Ben convinced her to stay and play, but eventually agreed to go home and have hot cocoa.\n",
      "Story: \n",
      "\n",
      "Sara and Ben were playing in the park. They liked to climb the big oak tree and pretend they were birds. They made nests with leaves and twigs and sang songs.\n",
      "But today, the sky was gloomy and the wind was cold. Sara felt sad and cold. She wanted to go home and have some hot cocoa.\n",
      "\"Ben, I want to quit,\" she said. \"It's too cold and dark. Let's go home.\"\n",
      "Ben looked at Sara and frowned. He liked the oak tree and the park. He wanted to stay and play.\n",
      "\"No, Sara, don't quit,\" he said. \"It's fun here. Look, there's a squirrel. Let's chase it.\"\n",
      "Sara shook her head. She didn't want to chase the squirrel. She wanted to go home and have some hot cocoa.\n",
      "\"Please, Ben, let's go home,\" she said. \"We can play here another day. I'm cold and hungry.\"\n",
      "Ben saw that Sara was shivering and looked unhappy. He loved his sister and didn't want her to be sad. He nodded and smiled.\n",
      "\"Okay, Sara, let's go home,\" he said. \"We can have some hot cocoa and cookies. And we can play with our toys.\"\n",
      "Sara hugged Ben and thanked him. They climbed down the oak tree and ran to their mom, who was waiting for them. They told her about their adventure and asked for some hot cocoa and cookies. Mom smiled and agreed. She was proud of her children for being brave and kind. They went home and had a cozy and happy time.\n",
      "<|endoftext|>\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 21755681\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 218380\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset['train']))\n",
    "\n",
    "for i in range(16):\n",
    "    print(dataset['train'][i]['text']) # type: ignore\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done tokenizing\n"
     ]
    }
   ],
   "source": [
    "dat_tok = tokenizer(dataset['train']['text'], return_attention_mask=False)\n",
    "print('done tokenizing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_train_tokenized.txt', 'wb') as output_file:\n",
    "    pickle.dump(dat_tok, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done tokenizing\n"
     ]
    }
   ],
   "source": [
    "datt_tok = tokenizer(dataset['validation']['text'], return_attention_mask=False)\n",
    "print('done tokenizing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_test_tokenized.txt', 'wb') as output_file:\n",
    "    pickle.dump(datt_tok, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
